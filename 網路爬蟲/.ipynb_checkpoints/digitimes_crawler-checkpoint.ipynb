{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.72 Safari/537.36', \n",
    "          'Host': 'www.digitimes.com.tw', 'Cookie': 'vid=632200fc52cf6203; ASPSESSIONIDSUTQRBTC=KFHKBKMCGFKDGJGGCOFCMPDO; _ga=GA1.3.891328288.1618882950; _gid=GA1.3.1552164631.1618882950; autorefresh=null; new_a1=new_a1; ASPSESSIONIDQEQAQDAR=HIKKOHADPMJMGPGJCGCAJECG; DownMYID=kaihsu%40inpaq%2Ecom%2Etw; MyID=Bl9%6002jP9GgSQVNt5WWEPt5OO7RSAVGXWY8RhY5OJKSP2oL9RE3J0VFoJB8N31380LbPSDLTF22VWQpZNGSYOMNEFEI%2FNFJ1JNCF7CFU1bWZWY10KYD44W0ApNDI4I7535RBD9T8lK1KXXTUFQVO6VG3S%2FV7ZZVNKS53QZNNZR0sM8TKZAFSD6X0Y2F4Y7xSX37RFIHJFR6DJ72H5J; MemRights=KPS; yUID=kaihsu%40inpaq%2Ecom%2Etw; promotype=N; MyName=%B3%5C%B3%CD%B4%BC; sShow=Y; MemberIDPDF=XCA96133; SSLUID=XCA64039; occupation=30; MyPwd=BJEm5LqIR0%60F92IrXXSJK00XCRZK3114FQBH2YGH6FNAU5GTCFOBGAP; sLgnTime=2021%2F4%2F20+%A4W%A4%C8+11%3A04%3A47; MemSID=813606345; UserIDPDF=XCA64039; NewMemRights=1%2C9%2C3%2C4%2C10%2C13%2C17%2C99; DownMemID=XCA96133; DownUID=XCA64039; MyName%5Fcn='}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digitimes首頁登入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.digitimes.com.tw/tech/default.asp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_titles = soup.find_all('div', class_='col-md-12 col-sm-12 col-xs-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['日期', '分類', '新聞標題', '新聞內容']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "domain = 'https://www.digitimes.com.tw'\n",
    "for n in news_titles:\n",
    "    title = n.find('p', style='padding:0;').text\n",
    "    link = domain + n.find('a')['href']\n",
    "    res = requests.get(link, headers=headers)\n",
    "    soup = bs(res.content, 'html.parser')\n",
    "    category = soup.find('ul', class_='breadcrumb').find_all('li')[-1].text.strip()\n",
    "    date = soup.find('ul', class_='list-inline m-b-5 txt-16').find_all('li')[-1].text\n",
    "    content = soup.find('div', id='newsText')  \n",
    "    text = content.find_all('p', class_='main_p')\n",
    "    result = []\n",
    "    for t in text:\n",
    "        result.append(t.text)\n",
    "    result = ''.join(result).strip()\n",
    "    data = [date, category, title, result]\n",
    "    s = pd.Series(data, index=columns)\n",
    "    df = df.append(s, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['新聞內容'] = df['新聞內容'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('digitimes_latest_news.xlsx', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 電子時報爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.digitimes.com.tw/tech/dt/dtpage_cold.asp?CnlID=66'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = soup.find_all('td', style='padding-top:3px;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['日期', '分類', '作者', '新聞標題', '新聞內容']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://www.digitimes.com.tw'\n",
    "for t in titles:\n",
    "    news_title = t.find('a')\n",
    "    if news_title is None:\n",
    "        pass\n",
    "    else:\n",
    "        news_title = t.find('a').text\n",
    "        link = domain + t.find('a')['href']\n",
    "    try:\n",
    "        date = t.find('div', class_='small').text.split('-')[0]\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        data = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    try:\n",
    "        author = t.find('div', class_='small').text.split('-')[-1]\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    res = requests.get(link, headers=headers)\n",
    "    soup = bs(res.content, 'html.parser')\n",
    "#     author = soup.find('ul', class_='au_time list-inline m-b-5 txt-16 p-t-5 p-b-10').find('a').text\n",
    "    category = soup.find('ul', class_='breadcrumb').find_all('li')[-1].text.strip()\n",
    "    content = soup.find('div', id='newsText')  \n",
    "    text = content.find_all('p', class_='main_p')\n",
    "    result = []\n",
    "    for t in text:\n",
    "        result.append(t.text)\n",
    "    result = ''.join(result).strip()\n",
    "    data = [date, category, author, news_title, result]\n",
    "    s = pd.Series(data, index=columns)\n",
    "    df = df.append(s, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['新聞內容'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(datetime.now().strftime('%Y-%m-%d') + '_digitimes_daily_news.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
